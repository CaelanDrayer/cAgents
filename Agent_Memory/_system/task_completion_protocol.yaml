# UNIVERSAL TASK COMPLETION PROTOCOL
# Version 2.0 - Token-Based Metrics
# Applies to ALL domains: software, creative, business, marketing, sales, finance, operations, HR, legal, support

protocol_name: "Mandatory Task Completion Protocol"
version: "2.0"
enforcement: MANDATORY
scope: "All domains, all tiers, all agents"
owner: "Universal Executor"
enforced_by: ["universal-executor", "universal-validator", "orchestrator"]

## CORE PRINCIPLE
# A task is ONLY completed when 100% of acceptance criteria are met with verified evidence.
# NO partial completion. NO "mostly done". NO "almost finished".

completion_definition:
  description: "A task is completed if and only if ALL of these conditions are true"

  conditions:
    all_acceptance_criteria_met:
      requirement: "Every criterion from plan.yaml verified with concrete evidence"
      verification: "Each criterion has status=MET and specific evidence"
      no_exceptions: true

    all_outputs_exist:
      requirement: "Every required output file exists in the expected location"
      verification: "File existence checked, not just assumed"
      no_exceptions: true

    output_quality_verified:
      requirement: "Outputs are complete, production-quality, not placeholders or drafts"
      checks:
        - "Non-empty files"
        - "No TODO/FIXME markers (unless explicitly allowed)"
        - "No placeholder text like 'To be implemented'"
        - "Ready for downstream consumption"
      no_exceptions: true

    dependencies_satisfied:
      requirement: "If this task is a dependency for others, it provides everything needed"
      verification: "Downstream tasks can start immediately with provided outputs"
      no_exceptions: true

    no_blockers_remain:
      requirement: "All issues resolved, no pending work"
      verification: "No known issues, errors, or incomplete work"
      no_exceptions: true

    token_budget_respected:
      requirement: "Task completed within reasonable token budget (< 2x planned)"
      verification: "actual_tokens_used documented and reasonable"
      escalation: "If > 2x budget, investigate inefficiency"

## VERIFICATION REQUIREMENTS

verification_process:
  description: "MANDATORY steps before marking any task as completed"

  step_1_create_manifest:
    location: "outputs/partial/{task_id}/manifest.yaml"
    required_sections:
      completion_verification:
        description: "Map each acceptance criterion to verification evidence"
        format:
          criterion_id:
            status: "MET or NOT_MET"
            evidence: "Concrete, specific evidence (file path, test output, line numbers)"
            verified_at: "ISO 8601 timestamp"
        example: |
          completion_verification:
            criterion_1:
              status: MET
              evidence: "API endpoint implemented at src/api/auth.py:45-120, returns JWT token"
              verified_at: "2026-01-12T10:30:00Z"
            criterion_2:
              status: MET
              evidence: "Tests pass: 15/15 in test_auth.py, coverage 95%"
              verified_at: "2026-01-12T10:35:00Z"

      outputs_created:
        description: "List all output files created by this task"
        format: "Array of absolute or relative file paths"
        verification: "Each file MUST be verified to exist"
        example: |
          outputs_created:
            - outputs/partial/task_001/api.py
            - outputs/partial/task_001/test_api.py
            - outputs/partial/task_001/api_documentation.md

      quality_checks_passed:
        description: "Boolean indicating all quality checks passed"
        requirement: "MUST be true to mark task completed"
        checks:
          - "Code compiles/runs without errors"
          - "Tests pass (if applicable)"
          - "Linting passes (if applicable)"
          - "No obvious bugs or issues"
        example: "quality_checks_passed: true"

      token_metrics:
        description: "MANDATORY token usage tracking"
        required_fields:
          actual_tokens_used:
            type: "integer"
            description: "Actual tokens consumed during task execution"
            requirement: "MUST be provided for every completed task"
            example: "actual_tokens_used: 12450"

          token_budget:
            type: "integer"
            description: "Budgeted tokens for this task"
            example: "token_budget: 15000"

          token_efficiency:
            type: "float"
            description: "Ratio of actual to budgeted (actual / budget)"
            calculation: "actual_tokens_used / token_budget"
            target: "< 1.10 (within 10% of budget)"
            example: "token_efficiency: 0.83"

          token_complexity_score:
            type: "integer"
            description: "Difficulty rating (1-10) based on token requirements"
            calculation: "Based on token_based_metrics_system.yaml scoring"
            example: "token_complexity_score: 6"

          token_breakdown:
            type: "object"
            description: "Optional detailed breakdown of token usage"
            fields:
              context_loading: "Tokens for reading/understanding context"
              analysis: "Tokens for analysis/planning"
              generation: "Tokens for code/content generation"
              validation: "Tokens for testing/verification"
            example: |
              token_breakdown:
                context_loading: 3000
                analysis: 2500
                generation: 5000
                validation: 1950

  step_2_verify_files:
    action: "Check that every file in outputs_created actually exists"
    method: "Use Read or file existence check"
    failure_action: "If any file missing, keep task as in_progress"

  step_3_verify_criteria:
    action: "Check that every acceptance criterion has status=MET"
    method: "Review completion_verification section"
    failure_action: "If any criterion NOT_MET, keep task as in_progress"

  step_4_verify_quality:
    action: "Check that quality_checks_passed is true"
    method: "Review quality checks section"
    failure_action: "If false or missing, keep task as in_progress"

  step_5_verify_token_usage:
    action: "Check that actual_tokens_used is documented"
    method: "Review token_metrics section"
    failure_action: "If missing, keep task as in_progress"
    warning: "If token_efficiency > 1.5, flag for review"

## ENFORCEMENT RULES

enforcement_rules:
  rule_1_no_partial_completion:
    statement: "A task is either FULLY completed or NOT completed"
    explanation: "There is no intermediate state like 'mostly done' or '90% complete'"
    allowed_statuses:
      - "pending: Task not yet started"
      - "in_progress: Task started but not all criteria met"
      - "completed: ALL criteria met and verified"
      - "failed: Task cannot be completed (after retries)"
    prohibited_states:
      - "mostly done"
      - "90% complete"
      - "almost finished"
      - "just needs polish"
    consequence: "If even ONE criterion unmet, status MUST be in_progress, not completed"

  rule_2_evidence_required:
    statement: "Every acceptance criterion MUST have concrete, specific evidence"
    evidence_requirements:
      specificity: "Must reference specific files, line numbers, test outputs, metrics"
      verifiable: "Another agent could verify the evidence independently"
      concrete: "Not generic statements"

    acceptable_evidence_examples:
      - "File exists at src/api/auth.py with 150 lines implementing JWT authentication"
      - "Tests pass: pytest output shows 45/45 passed, 0 failed"
      - "Performance benchmark shows 95th percentile latency under 100ms"
      - "Database migration applied successfully, schema verified in production"

    prohibited_evidence_examples:
      - "Looks good"
      - "Seems to work"
      - "Probably correct"
      - "Should be fine"
      - "Appears complete"

    consequence: "Evidence that's too generic causes validation failure"

  rule_3_all_or_nothing:
    statement: "Task marked completed ONLY when 100% of criteria met"
    conditions:
      if_any_criterion_not_met: "Task status = in_progress or failed"
      if_any_output_missing: "Task status = in_progress or failed"
      if_any_quality_check_fails: "Task status = in_progress or failed"
      if_dependencies_not_satisfied: "Task status = in_progress or failed"
      if_token_usage_missing: "Task status = in_progress (cannot validate without metrics)"
    explanation: "Even 99% complete is NOT complete. Must be 100%."

  rule_4_document_incomplete_work:
    statement: "If task cannot be completed, document EXACTLY what's missing"

    when_task_cannot_complete:
      blocked: "External dependency or blocker prevents completion"
      scope_too_large: "Task scope was underestimated, needs splitting"
      requirements_unclear: "Acceptance criteria are ambiguous or conflicting"
      token_budget_exhausted: "Exceeded reasonable token budget (> 2x planned)"

    required_actions:
      - action: "Document what WAS completed"
        location: "manifest.yaml with partial completion status"
      - action: "Document what REMAINS to be done"
        location: "manifest.yaml with outstanding_work section"
      - action: "Document actual token usage even if incomplete"
        location: "manifest.yaml with token_metrics section"
      - action: "Choose appropriate resolution"
        options:
          retry: "If transient issue, increment retry count and try again"
          split: "If too large, create new task for remaining work"
          escalate: "If blocked, escalate to HITL with blocker details"
          mark_failed: "If fundamentally cannot complete"
      - action: "NEVER mark as completed with work remaining"
        enforcement: "ABSOLUTE RULE"

## SUBAGENT SPAWNING

subagent_prompt_requirements:
  description: "When executor spawns subagents, MUST include completion protocol in prompt"

  required_sections:
    acceptance_criteria:
      header: "ACCEPTANCE CRITERIA (ALL MUST BE MET)"
      content: "List all criteria from plan.yaml with explicit requirement: ALL must be met"

    mandatory_requirements:
      header: "MANDATORY COMPLETION REQUIREMENTS"
      content: |
        - Complete ALL acceptance criteria (not partial)
        - Create ALL required outputs
        - Verify outputs are complete and production-quality
        - Include verification evidence in manifest.yaml
        - Document token usage in manifest.yaml
        - Only signal completion when 100% done

    required_output:
      header: "REQUIRED OUTPUT"
      content: |
        Location: Agent_Memory/{instruction_id}/outputs/partial/{task_id}/

        MUST include manifest.yaml with:
        - token_metrics:
            - actual_tokens_used: (integer)
            - token_budget: (integer)
            - token_efficiency: (float)
            - token_complexity_score: (1-10)
        - completion_verification: {criterion: {status, evidence, verified_at}}
        - outputs_created: [list of file paths]
        - quality_checks_passed: true/false
        - outstanding_work: (if any remains)

    token_budget_notice:
      header: "TOKEN BUDGET"
      content: |
        Token Budget: {budget} tokens
        - This is an estimate based on task complexity
        - Stay within reasonable limits (< 2x budget)
        - Report actual usage in manifest.yaml
        - If approaching 2x budget, consider:
          - Simplifying approach
          - Splitting into subtasks
          - Escalating for guidance

    completion_warning:
      header: "CRITICAL WARNING"
      content: |
        DO NOT mark work as done if any criterion is unmet.
        DO NOT mark work as done if any output is missing.
        DO NOT mark work as done without documenting token usage.
        Document what's incomplete and why if you cannot finish.
        Only mark as completed when 100% of criteria are met.

  prompt_template: |
    {Task description and context}

    ACCEPTANCE CRITERIA (ALL MUST BE MET):
    {List each criterion from plan}

    MANDATORY COMPLETION REQUIREMENTS:
    - Complete ALL acceptance criteria (not partial)
    - Create ALL required outputs
    - Verify outputs are complete and production-quality
    - Include verification evidence in manifest.yaml
    - Document token usage accurately
    - Only signal completion when 100% done

    TOKEN BUDGET: {budget} tokens
    - Estimated based on task complexity
    - Stay within reasonable limits (< 2x)
    - Report actual usage in manifest.yaml
    - Monitor your token consumption

    Output to: Agent_Memory/{instruction_id}/outputs/partial/{task_id}/

    REQUIRED OUTPUT:
    - manifest.yaml with:
      - token_metrics:
          - actual_tokens_used: (integer, REQUIRED)
          - token_budget: (integer)
          - token_efficiency: (float)
          - token_complexity_score: (1-10)
      - completion_verification: {criterion: status, evidence}
      - outputs_created: [list of files]
      - quality_checks_passed: true/false

    DO NOT mark work as done if any criterion is unmet.
    DO NOT mark work as done without token usage documentation.
    Document what's incomplete and why if you cannot finish.

## VALIDATOR INTEGRATION

validator_checks:
  description: "How universal-validator enforces this protocol"

  step_1_verify_manifests_exist:
    check: "Every completed task has manifest.yaml"
    location: "outputs/partial/{task_id}/manifest.yaml"
    failure: "If missing, mark validation as BLOCKED, escalate to HITL"

  step_2_verify_completion_sections:
    check: "Every manifest has completion_verification section"
    requirement: "Section must exist and be populated"
    failure: "If missing, mark validation as BLOCKED"

  step_3_verify_criteria_met:
    check: "Every criterion has status=MET with evidence"
    requirement: "All criteria must be MET, none can be NOT_MET"
    failure: "If any NOT_MET, mark validation as BLOCKED"

  step_4_verify_files_exist:
    check: "Every file in outputs_created actually exists"
    method: "Use Read tool or file existence check"
    failure: "If any missing, mark validation as BLOCKED"

  step_5_verify_quality_passed:
    check: "quality_checks_passed is true"
    requirement: "Boolean must be true"
    failure: "If false or missing, mark validation as BLOCKED"

  step_6_verify_token_metrics:
    check: "token_metrics section exists and is complete"
    required_fields:
      - "actual_tokens_used (integer, > 0)"
      - "token_budget (integer, > 0)"
      - "token_efficiency (float)"
      - "token_complexity_score (1-10)"
    failure: "If any field missing, mark validation as BLOCKED"
    warning: "If token_efficiency > 1.5, flag for efficiency review"

  escalation_on_failure:
    action: "If any verification check fails, escalate to HITL"
    reason: "Executor did not properly verify task completion"
    include_in_report:
      - "Which tasks failed verification"
      - "Which specific checks failed"
      - "What evidence was missing or insufficient"
      - "Token efficiency concerns (if applicable)"

## ORCHESTRATOR INTEGRATION

orchestrator_checks:
  description: "How orchestrator enforces protocol during phase transitions"

  before_executing_to_validating:
    check_1: "All planned tasks are in tasks/completed/"
    check_2: "All completed tasks have manifest.yaml with verification"
    check_3: "All manifests include token_metrics with actual_tokens_used"
    check_4: "output_summary.yaml exists and lists all outputs"
    check_5: "No tasks remain in tasks/pending/ or tasks/in_progress/"

    failure_action: "DO NOT transition to validating phase"
    escalation: "Escalate to HITL with specific failures documented"

## QUALITY GATES

quality_checklist:
  description: "Checklist executor must verify before marking task completed"

  checklist_items:
    - item: "All acceptance criteria met with evidence"
      verification: "Review completion_verification in manifest"
      critical: true

    - item: "All required outputs exist and are non-empty"
      verification: "Check each file in outputs_created"
      critical: true

    - item: "Outputs are production-quality (not drafts/placeholders)"
      verification: "Spot-check content, no TODO/FIXME unless allowed"
      critical: true

    - item: "Token usage documented accurately"
      verification: "Check token_metrics section in manifest"
      critical: true

    - item: "Token efficiency reasonable (< 1.5x budget)"
      verification: "Calculate token_efficiency ratio"
      critical: false

    - item: "Downstream dependencies will have what they need"
      verification: "Review plan to see what other tasks depend on this"
      critical: true

    - item: "Tests pass (if applicable)"
      verification: "Run tests, check exit code"
      critical: false

    - item: "No TODO/FIXME comments in deliverables"
      verification: "Grep for TODO/FIXME in outputs"
      critical: false

    - item: "Documentation updated (if required by criteria)"
      verification: "Check acceptance criteria for doc requirements"
      critical: false

## HANDLING INCOMPLETE TASKS

incomplete_task_handling:
  assessment:
    - check: "Why is task incomplete?"
      reasons:
        blocker: "External dependency or issue blocking progress"
        scope_large: "Task larger than estimated"
        requirements_unclear: "Criteria ambiguous or conflicting"
        token_budget_exceeded: "Consumed > 2x planned tokens"
        dependency_failed: "Upstream task failed or incomplete"

  resolution_strategies:
    retry:
      when: "Transient issue, likely to succeed on retry"
      action: "Increment retry count, clear transient errors, try again"
      limit: "Max 2-3 retries per task"

    split:
      when: "Task scope too large for single execution"
      action: "Create new task for remaining work, mark current as partial"
      process:
        - "Document what was completed"
        - "Document tokens consumed so far"
        - "Create new task with remaining criteria"
        - "Adjust token budgets for split tasks"
        - "Update dependencies"
        - "Mark original task as completed (for completed portion) or failed"

    escalate:
      when: "Blocked by external issue or cannot proceed"
      action: "Escalate to HITL with blocker details"
      include:
        - "What was attempted"
        - "What's blocking completion"
        - "Tokens consumed so far"
        - "What's needed to unblock"

    mark_failed:
      when: "Fundamentally cannot complete (even with retries)"
      action: "Mark task as failed, document reason"
      consequence: "Workflow will fail validation, escalate to HITL"

## CONSEQUENCES OF VIOLATIONS

violation_consequences:
  incomplete_marked_as_complete:
    detection: "Validator finds missing criteria or outputs"
    consequence: "Validation fails (FIXABLE or BLOCKED)"
    cost: "Self-correct or HITL intervention needed, wasted tokens"

  missing_verification_evidence:
    detection: "Validator finds generic or missing evidence"
    consequence: "Cannot verify completion, validation BLOCKED"
    cost: "Must redo verification, wasted tokens and effort"

  missing_token_metrics:
    detection: "Validator finds missing actual_tokens_used"
    consequence: "Cannot track performance, validation BLOCKED"
    cost: "Cannot optimize future token budgets, lost calibration data"

  partial_completion_accepted:
    detection: "Downstream tasks fail due to missing inputs"
    consequence: "Cascade of failures in dependent tasks"
    cost: "Multiple tasks must be redone, significant token waste"

## BENEFITS

protocol_benefits:
  quality_assurance: "Ensures all work is actually complete before proceeding"
  reduced_rework: "Catches incomplete work early, before downstream impact"
  clear_standards: "Removes ambiguity about what 'done' means"
  audit_trail: "Verification records provide clear evidence of completion"
  predictable_outcomes: "Workflows complete reliably or fail cleanly"
  token_efficiency: "Tracks token usage for optimization and cost management"
  calibration_data: "Builds historical data for better future estimates"

---

# PROTOCOL SUMMARY

## For Executors:
1. Before marking ANY task completed, verify ALL criteria with evidence
2. Create manifest.yaml with completion_verification for EVERY task
3. Include concrete evidence (files, test outputs, metrics) not generic "looks good"
4. **MANDATORY: Document actual_tokens_used in token_metrics section**
5. Verify all outputs actually exist before marking complete
6. Never mark as completed if ANY work remains - 100% or in_progress
7. Track and report token efficiency for continuous improvement

## For Validators:
1. Check ALL completed tasks have manifest.yaml with verification
2. Verify every criterion has status=MET with specific evidence
3. Verify all files in outputs_created actually exist
4. **NEW: Verify token_metrics section exists with actual_tokens_used**
5. If any verification fails, mark BLOCKED and escalate to HITL
6. Flag tasks with token_efficiency > 1.5 for review

## For Orchestrator:
1. Before executing â†’ validating transition, verify all manifests exist
2. Verify all tasks have completion_verification
3. **NEW: Verify all tasks have token_metrics with actual usage**
4. If verification missing, DO NOT transition, escalate to HITL

## The Golden Rules:
**100% completion with verified evidence, or it's not complete.**
**Token usage MUST be documented for every completed task.**
