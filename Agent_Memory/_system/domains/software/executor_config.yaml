# Software Domain Executor Configuration
# Execution coordination and agent invocation rules for software engineering

domain: software
version: 1.0
description: "Execution strategies and agent coordination for software development workflows"

# Agent Capabilities
# Defines what each software domain agent can do

agent_capabilities:
  # Development Team
  backend-developer:
    specializations: [api_development, server_logic, database_integration]
    tools: [Read, Write, Edit, Bash, Grep, Glob]
    workload_capacity: high
    typical_tasks: [create, modify, test]
    skill_areas: [python, javascript, nodejs, sql, rest_api, graphql]

  frontend-developer:
    specializations: [ui_development, client_logic, responsive_design]
    tools: [Read, Write, Edit, Bash]
    workload_capacity: high
    typical_tasks: [create, modify, test]
    skill_areas: [react, vue, html, css, javascript, typescript]

  senior-developer:
    specializations: [complex_implementation, code_review, mentoring, debugging]
    tools: [Read, Write, Edit, Bash, Grep, Glob, Task]
    workload_capacity: medium
    typical_tasks: [create, modify, analyze, validate, review]
    skill_areas: [full_stack, architecture, best_practices, patterns]

  # Architecture & Design
  architect:
    specializations: [system_design, api_design, pattern_selection, trade_off_analysis]
    tools: [Read, Grep, Glob, Write, Bash, Task]
    workload_capacity: medium
    typical_tasks: [analyze, design, review]
    skill_areas: [distributed_systems, microservices, scalability, security]

  # Domain Leads (Tier 3-4)
  frontend-lead:
    specializations: [frontend_planning, team_coordination, code_review]
    tools: [Read, Grep, Glob, Write, Bash, TodoWrite, Task]
    workload_capacity: medium
    typical_tasks: [coordinate, review, plan]
    scope: "Frontend team management and technical decisions"

  backend-lead:
    specializations: [backend_planning, api_design, team_coordination]
    tools: [Read, Grep, Glob, Write, Bash, TodoWrite, Task]
    workload_capacity: medium
    typical_tasks: [coordinate, review, plan]
    scope: "Backend team management and technical decisions"

  devops-lead:
    specializations: [infrastructure_planning, deployment_coordination, ci_cd]
    tools: [Read, Grep, Glob, Write, Bash, TodoWrite, Task]
    workload_capacity: medium
    typical_tasks: [coordinate, deploy, monitor]
    scope: "DevOps team and infrastructure management"

  data-lead:
    specializations: [database_architecture, data_pipeline_planning, team_coordination]
    tools: [Read, Grep, Glob, Write, Bash, TodoWrite, Task]
    workload_capacity: medium
    typical_tasks: [coordinate, design, review]
    scope: "Data team and database management"

  security-lead:
    specializations: [security_planning, threat_modeling, team_coordination]
    tools: [Read, Grep, Glob, Write, Bash, TodoWrite, Task]
    workload_capacity: medium
    typical_tasks: [coordinate, review, audit]
    scope: "Security team and security strategy"

  qa-lead:
    specializations: [test_strategy, qa_coordination, quality_gates]
    tools: [Read, Grep, Glob, Write, Bash, TodoWrite, Task]
    workload_capacity: medium
    typical_tasks: [coordinate, validate, review]
    scope: "QA team and testing strategy"

  # Technical Leadership
  engineering-manager:
    specializations: [strategic_oversight, risk_assessment, go_no_go_decisions]
    tools: [Read, Grep, Glob, Write, Bash, TodoWrite, Task]
    workload_capacity: low
    typical_tasks: [review, approve, escalate]
    scope: "Tier 3-4 strategic reviews and critical decisions"

  tech-lead:
    specializations: [delivery_coordination, priority_decisions, team_orchestration]
    tools: [Read, Grep, Glob, Write, Bash, TodoWrite, Task]
    workload_capacity: medium
    typical_tasks: [coordinate, prioritize, unblock]
    scope: "Tier 3-4 task assignment and team coordination"

  # Specialized Roles
  dba:
    specializations: [database_design, query_optimization, data_integrity]
    tools: [Read, Write, Edit, Bash]
    workload_capacity: medium
    typical_tasks: [create, modify, analyze, optimize]
    skill_areas: [sql, postgresql, mysql, mongodb, redis]

  data-analyst:
    specializations: [data_pipelines, analytics, business_intelligence]
    tools: [Read, Write, Bash]
    workload_capacity: medium
    typical_tasks: [create, analyze]
    skill_areas: [etl, reporting, data_visualization, sql]

  security-specialist:
    specializations: [vulnerability_assessment, secure_coding, penetration_testing]
    tools: [Read, Bash, Grep, Glob]
    workload_capacity: medium
    typical_tasks: [validate, review, audit]
    skill_areas: [owasp, encryption, authentication, authorization]

  ux-designer:
    specializations: [user_research, interface_design, usability_testing]
    tools: [Read, Write]
    workload_capacity: medium
    typical_tasks: [design, validate]
    skill_areas: [user_flows, wireframes, prototyping, accessibility]

  # Operations
  devops:
    specializations: [ci_cd, infrastructure_automation, deployment]
    tools: [Read, Write, Bash, Grep, Glob]
    workload_capacity: high
    typical_tasks: [create, deploy, monitor]
    skill_areas: [docker, kubernetes, terraform, jenkins, github_actions]

  sysadmin:
    specializations: [infrastructure_management, monitoring, incident_response]
    tools: [Read, Bash, Grep]
    workload_capacity: medium
    typical_tasks: [deploy, monitor, troubleshoot]
    skill_areas: [linux, networking, security, monitoring]

  # Documentation & Quality
  scribe:
    specializations: [documentation, knowledge_capture, technical_writing]
    tools: [Read, Write, Grep, Glob]
    workload_capacity: high
    typical_tasks: [create, modify]
    skill_areas: [technical_writing, api_documentation, markdown]

  reviewer:
    specializations: [code_review_orchestration, qa_coordination]
    tools: [Read, Grep, Glob, Write, TodoWrite, Task]
    workload_capacity: medium
    typical_tasks: [review, coordinate, validate]
    scope: "Comprehensive code review with 9 QA agents"

# Execution Strategies
# How tasks are executed based on tier and complexity

execution_strategies:
  tier_1_direct:
    description: "Executor handles simple tasks directly"
    when_to_use:
      tier: [1]
      task_complexity: simple
      estimated_time: "< 30 minutes"
    method: "Use tools directly (Read, Write, Edit, Bash)"
    delegation: false
    example: "Fix typo in README using Edit tool"

  tier_2_domain_delegation:
    description: "Delegate to appropriate domain specialist"
    when_to_use:
      tier: [2]
      task_complexity: moderate
      domain_expertise_required: true
    method: "Create delegation message to assigned agent's inbox"
    delegation: true
    coordination: "Monitor agent progress, aggregate outputs"
    example: "Delegate bug fix to backend-developer"

  tier_3_team_coordination:
    description: "Coordinate multiple agents through Tech Lead"
    when_to_use:
      tier: [3]
      multiple_parallel_tasks: true
      team_coordination_required: true
    method: "Hand off to tech-lead for team orchestration"
    delegation: true
    coordination: "Tech Lead assigns tasks, Executor monitors completion"
    example: "Tech Lead coordinates frontend + backend feature development"

  tier_4_full_orchestration:
    description: "Full team orchestration with domain leads and EM oversight"
    when_to_use:
      tier: [4]
      architectural_changes: true
      multi_phase_execution: true
    method: "Engineering Manager oversees, domain leads coordinate teams"
    delegation: true
    coordination: "EM provides oversight, domain leads manage execution"
    checkpoints: "After each phase, before critical decisions"
    example: "EM oversees database migration with backend-lead and data-lead"

# Output Aggregation Rules
# How to combine outputs from multiple tasks

output_aggregation:
  code_changes:
    description: "Code files modified or created"
    aggregation_method: "List all files changed with diffs"
    output_location: "outputs/final/code_changes.md"
    format: |
      # Code Changes Summary

      ## Files Modified
      - path/to/file1.py (150 lines changed)
      - path/to/file2.js (45 lines changed)

      ## Files Created
      - path/to/newfile.ts (200 lines)

      ## Tests Added
      - tests/test_feature.py (120 lines)

  test_results:
    description: "Test execution results"
    aggregation_method: "Combine test output from all test runs"
    output_location: "outputs/final/test_results.md"
    format: |
      # Test Results

      ## Unit Tests: PASS (45/45)
      ## Integration Tests: PASS (12/12)
      ## E2E Tests: PASS (8/8)
      ## Coverage: 92%

  documentation:
    description: "Documentation updates"
    aggregation_method: "Collect all documentation changes"
    output_location: "outputs/final/documentation.md"
    format: "Links to updated docs with change summaries"

  deployment_report:
    description: "Deployment execution summary"
    aggregation_method: "Deployment logs and validation results"
    output_location: "outputs/final/deployment_report.md"
    format: |
      # Deployment Report

      **Environment**: production
      **Deployed**: 2026-01-10 14:30 UTC
      **Status**: SUCCESS
      **Downtime**: 0 seconds
      **Smoke Tests**: PASS (10/10)

  comprehensive_summary:
    description: "Overall workflow execution summary"
    aggregation_method: "Combine all outputs with statistics"
    output_location: "outputs/final/execution_summary.md"
    format: |
      # Execution Summary

      **Tasks Completed**: 7/7
      **Files Modified**: 12
      **Tests Added**: 5
      **Test Coverage**: 92%
      **Code Review**: APPROVED
      **Security Review**: PASS
      **Documentation**: UPDATED

# Cross-Domain Invocation
# How to invoke agents from other domains when needed

cross_domain:
  enabled: true
  format: "{domain}:{agent_name}"

  common_cross_domain_scenarios:
    - scenario: "GDPR compliance implementation"
      primary_domain: software
      cross_domain_agents:
        - business:compliance-manager-business  # Policy framework
        - legal:privacy-officer  # Legal compliance review
      coordination: "Software executor invokes cross-domain agents for consultation"

    - scenario: "Sales dashboard development"
      primary_domain: software
      cross_domain_agents:
        - business:sales-operations-manager  # Requirements and metrics
        - marketing:marketing-analyst  # Marketing KPIs
      coordination: "Software executor gets requirements from business domain"

    - scenario: "Technical documentation for business process"
      primary_domain: business
      cross_domain_agents:
        - software:scribe  # Technical writing expertise
      coordination: "Business executor invokes software scribe for documentation"

  resolution_process:
    - step: "Parse assigned_agent field for domain prefix"
    - step: "Check if domain prefix exists (format: domain:agent-name)"
    - step: "Look up agent in global registry"
    - step: "Create cross-domain delegation message"
    - step: "Monitor completion in other domain"
    - step: "Integrate cross-domain output into primary workflow"

# Recursive Workflow Triggering
# When and how to create child workflows

recursive_workflows:
  enabled: true

  triggers:
    large_task_decomposition:
      condition: "Single task estimated > 4 hours"
      action: "Create child workflow for subtask"
      example: "Write 50-chapter novel → 50 child workflows (one per chapter)"

    cross_domain_coordination:
      condition: "Task requires work in multiple domains"
      action: "Create child workflow per domain"
      example: "GDPR compliance → software child + business child + legal child"

    iterative_refinement:
      condition: "Task requires multiple iterations"
      action: "Create child workflow for each iteration"
      example: "Performance optimization → child workflow per optimization pass"

    parallel_large_features:
      condition: "Multiple independent large features in tier 3-4"
      action: "Create child workflow per feature"
      example: "Implement 5 major features → 5 child workflows"

  api:
    function: "create_child_instruction"
    invocation: "Task tool with subagent_type=trigger"
    parameters:
      parent_instruction_id: "Current instruction ID"
      raw_input: "Subtask description"
      domain: "software (or other domain)"
      priority: "normal|high|critical"
      metadata:
        triggered_by: "universal-executor"
        reason: "Task decomposition / cross-domain / iteration"

  limits:
    max_depth: 5  # Maximum recursion levels
    max_children_per_parent: 100  # Max child workflows from one parent (increased from 20)
    batch_size: 20  # Process children in batches to avoid overwhelming system
    circular_reference_check: true  # Prevent circular workflows
    batching_enabled: true  # When children > batch_size, process in sequential waves

  parent_tracking:
    location: "Agent_Memory/{parent_id}/children/"
    file: "child_workflows.yaml"
    content: |
      total: 3
      completed: 1
      in_progress: 2
      blocked: 0
      children:
        - id: inst_001
          status: completed
        - id: inst_002
          status: in_progress
        - id: inst_003
          status: in_progress

# Timeout and Monitoring
# How long to wait and how to monitor progress

timeouts:
  agent_response:
    tier_1: "15 minutes"
    tier_2: "30 minutes"
    tier_3: "60 minutes"
    tier_4: "2 hours"
    default: "30 minutes"

  task_execution:
    simple: "30 minutes"
    moderate: "2 hours"
    complex: "4 hours"
    default: "1 hour"

  workflow_total:
    tier_1: "1 hour"
    tier_2: "4 hours"
    tier_3: "8 hours"
    tier_4: "1 week"

monitoring:
  progress_check_interval: "5 minutes"
  status_reporting_frequency: "After each task completion"
  blocker_detection: "Immediate (check every task start)"
  escalation_threshold: "After 2 failed retry attempts"

  health_checks:
    - check: "Agent responded within timeout"
    - check: "Task moved from pending to in_progress"
    - check: "Output files created in expected location"
    - check: "No error messages in agent logs"

# Error Handling
# How to handle different types of execution errors

error_handling:
  agent_timeout:
    detection: "Agent hasn't responded within timeout period"
    action_1: "Send reminder message to agent inbox"
    action_2: "Wait additional 50% of timeout"
    action_3: "Escalate to domain lead (tier 3-4) or mark blocked"
    logging: "Log timeout event with agent name and task ID"

  task_blocked:
    detection: "Agent reports task cannot be completed"
    action_1: "Move task to tasks/blocked/"
    action_2: "Document blocker reason"
    action_3: "Escalate to tech-lead (tier 3-4) or orchestrator"
    recovery: "Tech lead determines resolution path"

  agent_error:
    detection: "Agent reports error during execution"
    action_1: "Log error details"
    action_2: "Attempt retry once (if error seems transient)"
    action_3: "If retry fails, escalate to senior-developer"
    logging: "Capture full error stack trace"

  missing_dependency:
    detection: "Task depends on incomplete task"
    action_1: "Check if dependency task completed"
    action_2: "If not complete, wait and check again"
    action_3: "If dependency blocked, mark this task blocked too"
    recovery: "Resolve dependency blocker first"

  output_validation_failed:
    detection: "Agent completed but output doesn't meet acceptance criteria"
    action_1: "Document which criteria failed"
    action_2: "Create correction task"
    action_3: "Assign to same agent or senior-developer"
    escalation: "If correction fails, escalate to validator/self-correct"

  cross_domain_failure:
    detection: "Cross-domain agent invocation failed"
    action_1: "Verify other domain is available and agent exists"
    action_2: "Retry cross-domain delegation once"
    action_3: "Escalate to HITL if cross-domain coordination broken"
    logging: "Log cross-domain failure with both domains"

# Delegation Message Format
# Standard format for delegating tasks to agents

delegation_message:
  location: "Agent_Memory/_communication/inbox/{agent_name}/"
  filename: "{instruction_id}_{task_id}_delegation.yaml"
  format: |
    type: task_delegation
    from: universal-executor
    to: {agent_name}
    timestamp: {ISO8601}
    instruction_id: {inst_id}
    task_id: {task_id}

    task_description: "{description}"
    task_type: create|modify|analyze|validate|test

    specification:
      {task specification from plan}

    acceptance_criteria:
      - criterion1
      - criterion2

    deadline: {optional deadline}
    priority: normal|high|critical

    context:
      instruction_path: "Agent_Memory/{inst_id}/instruction.yaml"
      plan_path: "Agent_Memory/{inst_id}/workflow/plan.yaml"
      dependencies_completed: [list of completed dependency task IDs]

    authority:
      autonomy_level: 1.0  # Can make implementation decisions
      requires_approval: false  # Unless tier 4

# MANDATORY TASK COMPLETION PROTOCOL
# ALL executors MUST follow this protocol - it is NON-NEGOTIABLE

task_completion_protocol:
  version: "1.0"
  enforcement: MANDATORY

  completion_definition:
    description: "A task is completed if and only if ALL conditions are met"
    required_conditions:
      - all_acceptance_criteria_met: "Every criterion verified with concrete evidence"
      - all_outputs_exist: "Every required output file exists in expected location"
      - output_quality_verified: "Outputs complete, not empty or placeholder"
      - dependencies_satisfied: "Downstream tasks have everything they need"
      - no_blockers_remain: "All issues resolved, no pending work"

  verification_requirements:
    description: "Before marking task completed, executor MUST create verification record"
    required_in_manifest:
      - completion_verification:
          format: "Map of criterion → {status: MET/NOT_MET, evidence: string, verified_at: timestamp}"
          example: |
            completion_verification:
              criterion_1:
                status: MET
                evidence: "File exists at outputs/partial/task_001/api.py with 150 lines"
                verified_at: "2026-01-12T10:30:00Z"
      - outputs_created:
          format: "List of all output file paths created"
          verification: "Each file MUST actually exist"
      - quality_checks_passed:
          format: "Boolean indicating all quality checks passed"
          requirement: "MUST be true to mark task completed"
      - actual_context_used:
          format: "Number of tokens consumed"
          purpose: "Track context usage against budget"

  enforcement_rules:
    rule_1_no_partial_completion:
      statement: "A task is either FULLY completed or NOT completed"
      prohibited: ["mostly done", "90% complete", "almost finished"]
      allowed_statuses: ["pending", "in_progress", "completed", "failed"]

    rule_2_evidence_required:
      statement: "Every acceptance criterion MUST have concrete evidence"
      evidence_must_be: "Specific (file path, line numbers, test output, etc.)"
      prohibited_evidence: ["looks good", "seems correct", "probably works"]

    rule_3_all_or_nothing:
      statement: "Task marked completed ONLY when 100% of criteria met"
      conditions:
        - if_any_criterion_not_met: "status = in_progress or failed"
        - if_any_output_missing: "status = in_progress or failed"
        - if_any_quality_check_fails: "status = in_progress or failed"

    rule_4_document_incomplete_work:
      statement: "If task cannot be completed, document EXACTLY what's missing"
      actions:
        - "Create new task for remaining work"
        - "Update plan if requirements changed"
        - "NEVER mark as completed with work remaining"

  subagent_prompt_requirements:
    description: "When spawning subagents, MUST include completion protocol in prompt"
    required_sections:
      - "ACCEPTANCE CRITERIA (ALL MUST BE MET)"
      - "MANDATORY COMPLETION REQUIREMENTS"
      - "REQUIRED OUTPUT (manifest.yaml with verification)"
      - "DO NOT mark work as done if any criterion is unmet"

# Domain-Specific Notes
domain_notes: |
  Software domain execution considerations:

  **CRITICAL: Task Completion Protocol**:
  - Before marking ANY task completed, verify ALL acceptance criteria
  - Create manifest.yaml with completion_verification for EVERY task
  - Include concrete evidence for each criterion (not generic "looks good")
  - Verify all output files actually exist before marking complete
  - Never mark tasks as "mostly done" - 100% completion or in_progress

  **Agent Selection**:
  - Use assigned_agent from plan when specified (planner/tech-lead made decision)
  - For tier 1-2 without assignment: Route by task type and domain (frontend, backend, etc.)
  - For tier 3-4: Always involve tech-lead or domain leads for coordination

  **Parallel Execution**:
  - Frontend and backend tasks can run simultaneously
  - Multiple features can be developed in parallel
  - Tests can run while documentation is being written

  **Critical Path Management**:
  - Database changes often block other work (schema migrations)
  - Architecture decisions block implementation
  - Integration must wait for all components

  **Tool Usage**:
  - Tier 1: Executor can use tools directly (Read, Write, Edit)
  - Tier 2+: Delegate to specialist agents who use tools
  - Always use appropriate tools for task (Bash for tests, Edit for code changes)

  **Output Aggregation**:
  - Collect all code changes into single summary
  - Aggregate test results (unit, integration, E2E)
  - Combine documentation updates
  - Create comprehensive execution summary

  **Common Patterns**:
  - Bug fix: Delegate to developer → Run tests → Validate
  - Feature: Coordinate frontend + backend → Integrate → Test → Review
  - Refactor: Architect review → Implement → Verify tests pass
  - Deployment: Pre-checks → Deploy → Post-validation → Monitor

  **Error Recovery**:
  - Build failures: Re-run once, then escalate
  - Test failures: Fix and re-test, escalate after 2 failures
  - Deployment failures: Auto-rollback, investigate
  - Agent timeouts: Reminder → Wait → Escalate

  **Best Practices**:
  - Always check task dependencies before starting
  - Monitor agent progress regularly
  - Aggregate outputs incrementally
  - Log all errors with full context
  - Escalate blockers quickly to domain leads
  - Use TodoWrite to show execution progress
